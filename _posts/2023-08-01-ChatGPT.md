---
layout: post
title: ChatGPT
tags: [study, GPT, llama, instructGPT]
comments: true
---

## ChatGPT 
# 강의 요약 : [😎ChatGPT는 어떻게 학습할까요_ChatGPT 대화형 언어모델 소개 (feat, 챗봇)😎](https://www.youtube.com/watch?v=vziygFrRlZ4)

# InstructGPT
- from GPT 3.5
- RLHF : Reinforcement Learning by Human Feedback
    - Supervised Fine- Tuning, Reward Model, Proximal Policy Optimization Algorithm

# ChatGPT
- InstructGPT difference : Optimizing Language Models for Dialogue
- RLHF : Reinforcement Learning by Human Feedback
    - SFT : Supervised Fine- Tuning (사람이 대화셋트 만듦, GPT 3.5 로 코드 언어로 학습함.)
        - 데이터 수집
        - 모델 선택 : GPT-3.5 모델 선택, 프로그래밍 코드로부터 파인 튜닝된 text-davinci-003 추정
        - 사람이 직접 라벨링하기 때문에 고비용
        - InstructGPT로 긴 문장을 사람이 쓴 데이터를 이용함.
        - Fine tuning 한 모델이 나옴.
    - RM : Reward Model : 랭킹 매김. 
        - 문장 생성
        - 랭킹 라벨링 (사람이 랭킹을 매김)
        - RM 학습
    - PPO : Proximal Policy Optimization Algorithm : 강화학습 적용 (새 프롬프트 -PPO->Proximal Policy Optimizer -SFT + PPO-> Generate output -RM-> calculate reward -update->)
        - SFT + PPO 붙여서 추가로 파인튜닝
        - RM 모델의 평가
        - PPO 알고리즘 : 강화학습 정책 알고리즘, 에이전트가 수행하는 작업과 받는 보상을 기반으로 현재 정책을 지속적으로 학습
- Generative Pre-trained Transformer
    - 다음 단어를 예측
    - 많은 양의 데이터를 사전에 훈련
    - 신경망에 기반한 인코더-디코더
    - 대화할 수 있게 GPT를 fine tuning
- Transformer~ GPT
    - GPT-1 : 1억개 parameter (5GB data, 12 blocks 반복, 512 tokens)
    - GPT-2 : 15억개 (40GB data, 48 blocks, 1024 tokens)
    - GPT-3 : 1750억개 (600GB data, 96 blocks, 2048 tokens)
    - InstructGPT -> GPT3.5 : 학습 방식에서 Instruct 가 주어지는것. (Supervised + Reinforcement)
    - ChatGPT
- `Reinforcement`
- 장단점
    - 장점
        - 정확한 문법으로 답한다.
        - 복잡한 지시사항 이해
        - mix match ideas
    - 단점 
        - 맞는답?
        - 창의적? 저작권?
        - 비용 적정?
    - Application
        - 블로그, 이메일, 보고서
        - 각종 자료 조사
        - 아이디어 조사
- 모델들
    - code-davinci-002 : 베이스 모델, 순수 코드 완성 작업에 적합
    - text-davinci-002 
    : code-davinci-002 에 기반한 Instruct GPT 모델
    - code-davinci-003 :  text-davinci-002 개선 (PPO(강화학습 적용), 많은 회사에서 이걸 사용해서 개발 중)
- `대화형 에이전트에 최적화` (Optimizing Language Models for Dialogue)
- GhatGPT vs InstructGPT : 기존의 InstructGPT는 잘못된 정보를 만들어내지만, ChatGPT는 잘못된 정보도 수정됨. 나쁜 문장을 수정해줌.