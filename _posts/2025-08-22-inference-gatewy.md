---
layout: post
title: Inference Gateway, llm-d
tags: []
comments: true
---

# Inference Gateway
## GKE Inference Gatewayë€?
- ì˜¤í”ˆ ì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°ê°€ ê°œë°œí•œ Kubernetes Gateway API Inference Extensionì…ë‹ˆë‹¤. êµ¬ê¸€ í´ë¼ìš°ë“œëŠ” ì´ë¥¼ GKE í™˜ê²½ì— ìµœì í™”í•˜ì—¬ GKE Inference Gatewayë¥¼ ê³µê°œ
- GKE í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ L7 ë¶€í•˜ ë¶„ì‚°ê¸°ì²˜ëŸ¼ ì‘ë™í•˜ë©°, ë‹¨ìˆœí•œ íŠ¸ë˜í”½ ë¶„ì‚°ì„ ë„˜ì–´ ëª¨ë¸ì˜ ë‚´ë¶€ ìƒíƒœê¹Œì§€ íŒŒì•…í•˜ì—¬ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê·¸ ê²°ê³¼ ì§€ëŠ¥ì ì¸ ë¼ìš°íŒ…, ìë™ í™•ì¥, ì•ˆì „ì„± ê²€ì‚¬ì™€ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ì„ í†µí•´ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë°°í¬ì™€ ê´€ë¦¬ë¥¼ ê°„ì†Œí™”í•©ë‹ˆë‹¤. ì¦‰, ê°œë°œìëŠ” ê¸°ì¡´ ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì„ ê·¸ëŒ€ë¡œ í™œìš©í•˜ë©´ì„œë„ ê³ ì„±ëŠ¥ AI ì„œë¹„ìŠ¤ë¥¼ ì†ì‰½ê²Œ ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
### í•µì‹¬ ê¸°ëŠ¥
1. AIì— ìµœì í™”ëœ ë¶€í•˜ ë¶„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¶€í•˜ ë¶„ì‚°ê¸°ì™€ ë‹¬ë¦¬ ê²Œì´íŠ¸ì›¨ì´ê°€ ê° ëª¨ë¸ ì„œë²„ì˜ Key-Value ìºì‹œ í™œìš©ë¥ ì´ë‚˜ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ìˆ˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•…í•˜ì—¬ ê°€ì¥ ì—¬ìœ  ìˆëŠ” ì„œë²„ë¡œ ìš”ì²­ì„ ì „ë‹¬í•©ë‹ˆë‹¤. ì´ ë°©ì‹ì„ í†µí•´ ì§€ì—° ì‹œê°„ì„ ë‹¨ì¶•í•˜ê³  ì²˜ë¦¬ëŸ‰ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²Œ ê°€ëŠ¥í•œ ì´ìœ ëŠ” ìºì‹œ ì ì¤‘ë¥ ì„ ë†’ì—¬ GPU ê°™ì€ ê°€ì†ê¸° ìì›ì„ í•œì¸µ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
2. ì¶”ë¡  ì§€í‘œì— ê¸°ë°˜í•œ ìë™ í™•ì¥ ê¸°ëŠ¥ë„ ì§€ì›í•©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ìš”ì²­ ìˆ˜ë¿ë§Œ ì•„ë‹ˆë¼, KV ìºì‹œ í™œìš©ë¥ ì´ë‚˜ í† í° ëŒ€ê¸°ì—´ ê¸¸ì´ ê°™ì€ ì¶”ë¡  íŠ¹í™” ì§€í‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ ì„œë²„(Pod) ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìš”ì²­ì´ ê¸‰ì¦í•  ë•ŒëŠ” ì‹ ì†í•˜ê²Œ ìì›ì„ ëŠ˜ë ¤ ì„œë¹„ìŠ¤ í’ˆì§ˆì„ ìœ ì§€í•˜ê³ , í•œì‚°í•  ë•ŒëŠ” ìì›ì„ ì¤„ì—¬ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. LoRA ëª¨ë¸ì˜ ë™ì  ì„œë¹™ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì„ í™œìš©í•˜ë©´ í•˜ë‚˜ì˜ ê¸°ë³¸ ëª¨ë¸ ìœ„ì— ì—¬ëŸ¬ ê°œì˜ ê²½ëŸ‰ LoRA ì–´ëŒ‘í„°ë¥¼ ë™ì ìœ¼ë¡œ íƒ‘ì¬í•˜ì—¬ ë™ì‹œì— ì„œë¹„ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ë ¹ ë™ì¼í•œ GPUì—ì„œ ì˜ì–´ ë¶„ì„ ëª¨ë¸ê³¼ ìŠ¤í˜ì¸ì–´ ë¶„ì„ ëª¨ë¸ì„ ë²ˆê°ˆì•„ ê°€ë©° ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë•ë¶„ì— í•œì •ëœ ê°€ì†ê¸° ìì›ì— ë” ë§ì€ ëª¨ë¸ì„ ë°°ì¹˜í•˜ì—¬ ìì› íš¨ìœ¨ê³¼ ë¹„ìš© íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. ëª¨ë¸ë³„ ë¼ìš°íŒ… ë° íŠ¸ë˜í”½ ê´€ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê²Œì´íŠ¸ì›¨ì´ê°€ HTTP ìš”ì²­ ë³¸ë¬¸ì„ ì§ì ‘ ë¶„ì„í•˜ì—¬, JSON í•„ë“œì— ì§€ì •ëœ ëª¨ë¸ ì´ë¦„ì„ ë³´ê³  í•´ë‹¹ ëª¨ë¸ì´ ìˆëŠ” ì„œë²„ ê·¸ë£¹ìœ¼ë¡œ ì •í™•íˆ ë¼ìš°íŒ…í•©ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ì—¬ëŸ¬ ë²„ì „ì˜ ëª¨ë¸ì„ A/B í…ŒìŠ¤íŠ¸í•˜ê±°ë‚˜, íŠ¹ì • ëª¨ë¸ì—ë§Œ íŠ¸ë˜í”½ì„ í• ë‹¹í•˜ëŠ” ë“± ìœ ì—°í•œ ë°°í¬ ì „ëµì„ ì†ì‰½ê²Œ ìš”ì²­ì˜ ì¤‘ìš”ë„ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„ ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  ìš”ì²­ì˜ ì¤‘ìš”ë„ê°€ ê°™ì§€ ì•Šë‹¤ëŠ” ì ì„ ê³ ë ¤í•˜ì—¬ ì¤‘ìš”ë¡œ í‘œì‹œëœ ìš”ì²­ì€ ì§€ì—°ì„ ìµœì†Œí™”í•˜ë©° ë¨¼ì € ì²˜ë¦¬í•˜ê³ , ëœ ì¤‘ìš”í•œ ë°°ì¹˜ ì‘ì—… ë“±ì€ ì‹œìŠ¤í…œ ë¶€í•˜ê°€ ë†’ì„ ë•Œ ì˜ë„ì ìœ¼ë¡œ ì§€ì—°ì‹œí‚¤ê±°ë‚˜ ê±°ë¶€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•œì •ëœ ìì› ì•ˆì—ì„œë„ í•µì‹¬ ì„œë¹„ìŠ¤ì˜ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
5. AI ë³´ì•ˆ ë° ì•ˆì „ì„± ê¸°ëŠ¥ì´ í†µí•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê²Œì´íŠ¸ì›¨ì´ ë‹¨ì—ì„œ êµ¬ê¸€ í´ë¼ìš°ë“œì˜ Model Armor ì„œë¹„ìŠ¤ì™€ ì—°ë™í•˜ì—¬, ëª¨ë“  í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µì— ëŒ€í•œ ìœ í•´ì„± ê²€ì‚¬ ë° ë¯¼ê°ì •ë³´ í•„í„°ë§ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ëª¨ë“  ëª¨ë¸ì— ì¼ê´€ëœ ë³´ì•ˆ ì •ì±…ì„ ì¤‘ì•™ì—ì„œ ì ìš©í•˜ë¯€ë¡œ, ê¸°ì—…ì€ ì•ˆì‹¬í•˜ê³  AI ì„œë¹„ìŠ¤ë¥¼ ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
6. ì¶”ë¡  íŠ¸ë˜í”½ì— íŠ¹í™”ëœ í†µí•© ê´€ì¸¡ì„±(Observability)ì„ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë¸ë³„ í† í° ì²˜ë¦¬ìœ¨, ëŒ€ê¸°ì—´ ê¸¸ì´, ìºì‹œ ì ì¤‘ë¥ ê³¼ ê°™ì€ ìƒì„¸ ì§€í‘œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ì—¬ ì„œë¹„ìŠ¤ì˜ ë³‘ëª© ì§€ì ì„ ì°¾ê³  ìš´ì˜ì„ ìµœì í™”í•˜ëŠ” ë° í•„ìš”í•œ í†µì°°ë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
## ì°¸ê³ 
- Inference Gateway : https://www.megazonesoft.com/250601-gkellm/

# llm-d
- 2025ë…„ Red Hat Summitì—ì„œ ê³µê°œëœ llm-d ì»¤ë®¤ë‹ˆí‹°ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ì—ì„œ ìƒì„±í˜• AI ì¶”ë¡  í˜ì‹ ì„ ê°€ì†í•˜ëŠ” ì¤‘ìš”í•œ ì§„ì „ì…ë‹ˆë‹¤. llm-dëŠ” vLLMê³¼ Inference Gateway ìœ„ì— êµ¬ì¶•ëìœ¼ë©°, Kubernetes ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ëŒ€ê·œëª¨ ì¶”ë¡  í™˜ê²½ì— ë§ì¶° vLLMì˜ ê¸°ëŠ¥ì„ í™•ì¥í•©ë‹ˆë‹¤.

## Prefill and Decode Disaggregation
ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”. **Prefill and Decode Disaggregation**ì€ LLM ì„œë¹™(íŠ¹íˆ vLLM, FasterTransformer, Megatron-LM ê°™ì€ ì‹œìŠ¤í…œ)ì—ì„œ ì¤‘ìš”í•œ ìµœì í™” ê°œë…ì…ë‹ˆë‹¤. ê°„ë‹¨íˆ ë§í•´, **"í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬(prefill)"ì™€ "ìƒì„±(decoding)" ë‹¨ê³„ë¥¼ ë¶„ë¦¬í•´ì„œ ì²˜ë¦¬í•œë‹¤**ëŠ” ëœ»ì´ì—ìš”.

---

## ğŸ”¹ LLM ìš”ì²­ ì²˜ë¦¬ ê³¼ì •

LLMì— í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  ì‘ë‹µì„ ì–»ì„ ë•Œ, í¬ê²Œ ë‘ ë‹¨ê³„ê°€ ìˆìŠµë‹ˆë‹¤:

1. **Prefill (Prompt Processing)**

   * ì‚¬ìš©ìê°€ ì…ë ¥í•œ \*\*ì „ì²´ í”„ë¡¬í”„íŠ¸(prompt tokens)\*\*ë¥¼ ëª¨ë¸ì— ë„£ì–´, \*\*KV ìºì‹œ(Key/Value cache)\*\*ë¥¼ ì²˜ìŒë¶€í„° ì±„ì›Œ ë„£ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.
   * ì´ ë‹¨ê³„ëŠ” **ë³‘ë ¬í™”ê°€ ì˜ ë˜ê³ , GPU í™œìš©ë„ê°€ ë†’ìŒ** (ëª¨ë“  í† í°ì„ ë™ì‹œì— ì²˜ë¦¬ ê°€ëŠ¥).
   * ì˜ˆ: "Explain quantum mechanics in simple terms" â†’ ì´ ë¬¸ì¥ì„ í† í°í™”í•´ì„œ í•œ ë²ˆì— í†µê³¼ì‹œí‚´.

2. **Decode (Token-by-Token Generation)**

   * ì´ì œ ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ ìºì‹œë¥¼ ë°”íƒ•ìœ¼ë¡œ **í•˜ë‚˜ì˜ í† í°ì”© ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±**í•©ë‹ˆë‹¤.
   * ê° ìŠ¤í…ì€ ì§ì „ í† í°ì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì— **ë³‘ë ¬ì„±ì´ ê±°ì˜ ì—†ìŒ**.
   * ì˜ˆ: "Quantum mechanics is ..." â†’ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡, ë‹¤ì‹œ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ ...

---

## ğŸ”¹ Disaggregation (ë¶„ë¦¬ ì²˜ë¦¬)ì˜ ì˜ë¯¸

ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë¸ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ í”„ë¡¬í”„íŠ¸(Prefill)ì™€ ì‘ë‹µ ìƒì„±(Decode)ì„ í•œ íì—ì„œ ì²˜ë¦¬í–ˆëŠ”ë°, ì´ê±¸ **ë¶„ë¦¬**í•˜ë©´ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤:

* **ìì› íš¨ìœ¨í™”**

  * Prefillì€ í•œ ë²ˆë§Œ í•˜ê³ , DecodeëŠ” ì—¬ëŸ¬ ìš”ì²­ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•©ì³ì„œ ì²˜ë¦¬ ê°€ëŠ¥.
  * íŠ¹íˆ ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ìš”ì²­í•  ë•Œ, í”„ë¡¬í”„íŠ¸ ê¸¸ì´ëŠ” ë‹¤ ë‹¬ë¼ë„ ìƒì„± ë‹¨ê³„ëŠ” ë¹„ìŠ·í•˜ê²Œ ë¬¶ì–´ì„œ ì²˜ë¦¬ ê°€ëŠ¥.

* **ìŠ¤ì¼€ì¤„ë§ ìµœì í™”**

  * ê¸´ í”„ë¡¬í”„íŠ¸(ì˜ˆ: ìˆ˜ì²œ í† í°)ì™€ ì§§ì€ í”„ë¡¬í”„íŠ¸ê°€ ì„ì—¬ ë“¤ì–´ì™€ë„, í”„ë¡¬í”„íŠ¸ ë‹¨ê³„ì™€ ìƒì„± ë‹¨ê³„ë¥¼ ë¶„ë¦¬í•˜ë©´ **ëŒ€ê¸° ì‹œê°„(latency)ì„ ì¤„ì¼ ìˆ˜ ìˆìŒ**.

* **ì„œë¹™ ì•ˆì •ì„±**

  * Prefillì€ compute-intensive, DecodeëŠ” latency-sensitiveì¸ë°, ë”°ë¡œ ê´€ë¦¬í•˜ë©´ GPU/TPU ìì› ë°°ë¶„ì´ ì‰¬ì›Œì§.

---

## ğŸ”¹ ì‹¤ì œ ì˜ˆì‹œ

* vLLM ê°™ì€ ì—”ì§„ì—ì„œ:

  * **Prefill ë‹¨ê³„:** ì…ë ¥ í† í°ì„ í•œ ë²ˆì— í†µê³¼ â†’ KV ìºì‹œì— ì €ì¥
  * **Decode ë‹¨ê³„:** KV ìºì‹œë§Œ í™œìš©í•´ í† í° í•œ ê°œì”© ìƒì„±
    â†’ ì´ë ‡ê²Œ ë¶„ë¦¬í•˜ë©´ batch scheduling, continuous batching, speculative decoding ê°™ì€ ìµœì í™” ê¸°ë²•ê³¼ ê²°í•© ê°€ëŠ¥

---

## âœ… ì •ë¦¬

**Prefill and Decode Disaggregation** =
LLM ì‹¤í–‰ì—ì„œ \*\*í”„ë¡¬í”„íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë‹¨ê³„(prefill)\*\*ì™€ \*\*ì‘ë‹µì„ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë‹¨ê³„(decode)\*\*ë¥¼ ë¶„ë¦¬í•´ì„œ ì‹¤í–‰í•˜ëŠ” ìµœì í™” ê¸°ë²•.

â†’ ì¥ì : **GPU íš¨ìœ¨â†‘, ì§€ì—°ì‹œê°„â†“, ë©€í‹°ìœ ì € ì²˜ë¦¬ ì•ˆì •ì„±â†‘**

---


ì¢‹ì•„ìš”! ì•„ë˜ëŠ” **vLLM / sGLang** ê¸°ì¤€ìœ¼ë¡œ â€œPrefillâ€“Decode ë¶„ë¦¬(disaggregation)â€ê°€ **ì‹¤ì œë¡œ ì–´ë–»ê²Œ êµ¬í˜„Â·ìŠ¤ì¼€ì¤„ë§**ë˜ëŠ”ì§€ í•œëˆˆì— ë³´ì´ë„ë¡ ì •ë¦¬í•œ íë¦„ë„, í•µì‹¬ ìë£Œêµ¬ì¡°, ê·¸ë¦¬ê³  ì˜ì‚¬ì½”ë“œì…ë‹ˆë‹¤. (ê°œë…ì€ ê°™ê³ , ìš©ì–´/ì˜µì…˜ì´ ì¡°ê¸ˆì”© ë‹¬ë¼ìš”.)

# 1) í° ê·¸ë¦¼: íŒŒì´í”„ë¼ì¸ê³¼ í

```
[Request In]
    â”‚
    â”œâ”€â”€ Tokenize â†’ Build Request (max_new_tokens, stop, sampling, etc.)
    â”‚
    â”œâ”€â”€ Prefill Queue (ëŒ€ëŸ‰ ë³‘ë ¬ ì²˜ë¦¬, throughput-oriented)
    â”‚         â”‚
    â”‚         â””â”€> Batcher (prefill batch êµ¬ì„±)
    â”‚               â””â”€> Forward(prefill) â†’ KV Cache write â†’ seq ìƒíƒœ: READY_TO_DECODE
    â”‚
    â””â”€â”€ Decode Queue (ìŠ¤í…ë³„ ì²˜ë¦¬, latency-oriented)
              â”‚
              â””â”€> Scheduler (step ë‹¨ìœ„ aggregate)
                    â””â”€> Forward(decode 1-step) â†’ next token â†’ Update KV/Logits
                         â”œâ”€ stop ì¡°ê±´ ì¶©ì¡±? â†’ FINISH
                         â””â”€ ì•„ë‹ˆë©´ â†’ Decode Queue ì¬ì‚½ì…(ë‹¤ìŒ ìŠ¤í…)
```

* **Prefill**: ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì „ í† í°ì„ í•œ ë²ˆì— í†µê³¼ â†’ **KV ìºì‹œ ì±„ì›€**. ëŒ€ëŸ‰ ë³‘ë ¬í™” ê°€ëŠ¥ â†’ **GPU í™œìš©ë„â†‘**
* **Decode**: í•œ ìŠ¤í…(1 í† í°)ì”© ìƒì„± â†’ **ë³‘ë ¬ì„±â†“, ë ˆì´í„´ì‹œ ë¯¼ê°**. ë‹¤ìˆ˜ ìš”ì²­ì„ stepë‹¨ìœ„ë¡œ **continuous batching**ìœ¼ë¡œ ë¬¶ì–´ ì²˜ë¦¬

# 2) í•µì‹¬ ìë£Œêµ¬ì¡°(ê°œë…)

* `Request`: í•œ ì‚¬ìš©ìì˜ ìš”ì²­(í”„ë¡¬í”„íŠ¸, max\_new\_tokens, stop ê·œì¹™, temperature ë“±)
* `Sequence`: ì‹¤í–‰ ë‹¨ìœ„. `state âˆˆ {PREFILL_PENDING, DECODING, FINISHED}`
* `KVCacheHandle`: (layer, head, seq\_len)-ë³„ **paged KV ìºì‹œ** í¬ì¸í„°(ë©”ëª¨ë¦¬ í˜ì´ì§€ ë‹¨ìœ„ í• ë‹¹/íšŒìˆ˜)
* `PrefillBatch`: ì—¬ëŸ¬ ìš”ì²­ì˜ **í”„ë¡¬í”„íŠ¸ í…ì„œ**ë¥¼ pad/packí•˜ì—¬ í•œ ë²ˆì— ì „íŒŒ
* `DecodeBatch`: ì—¬ëŸ¬ ì‹œí€€ìŠ¤ì˜ **ë§ˆì§€ë§‰ í† í°**ì„ ëª¨ì•„ step ì „íŒŒ
* `Scheduler/Batcher`: íì—ì„œ ë½‘ì•„ batchë¥¼ ë§Œë“¤ê³ , ë©”ëª¨ë¦¬(KV í˜ì´ì§€), í† í° ìˆ˜, SLA ê¸°ì¤€ìœ¼ë¡œ **í•©/ë¶„ë¦¬** ì˜ì‚¬ê²°ì •

# 3) ìŠ¤ì¼€ì¤„ëŸ¬ ë£¨í”„(ì˜ì‚¬ì½”ë“œ)

```python
while True:
    # 1) ìˆ˜ì‹ ëœ ìš”ì²­ì„ Prefill Queueì— ì ì¬
    drain_incoming_requests_into(prefill_q)

    # 2) Prefill ìš°ì„  ì‹¤í–‰ (GPUê°€ ë†€ì§€ ì•Šë„ë¡ í° ë©ì–´ë¦¬ ìš°ì„ )
    if not prefill_q.empty() and gpu_has_room():
        batch = make_prefill_batch(prefill_q, max_tokens_budget, max_batch_size)
        logits, kv_writes = model.forward_prefill(batch.prompt_tokens)
        kv_cache.commit(kv_writes)  # KV í˜ì´ì§€ í• ë‹¹/ê°±ì‹ 
        for seq in batch.sequences:
            seq.state = DECODING
            decode_q.push(seq)

    # 3) Decode ìŠ¤í… ì‹¤í–‰ (ë ˆì´í„´ì‹œ ë¯¼ê°; step ë‹¨ìœ„ ë¬¶ê¸°)
    if not decode_q.empty() and gpu_has_room():
        step_batch = make_decode_batch(decode_q, max_active_seqs, max_context_budget)
        logits, kv_writes = model.forward_decode(step_batch.last_tokens)
        kv_cache.commit(kv_writes)
        for seq, logit in zip(step_batch.sequences, logits):
            next_tok = sample_token(logit, seq.sampling_params)
            seq.append(next_tok)
            if is_stop(seq) or seq.gen_len >= seq.max_new_tokens:
                seq.state = FINISHED
                finalize(seq); free_kv_pages(seq)
            else:
                # ë‹¤ìŒ stepì„ ìœ„í•´ ë‹¤ì‹œ decode íë¡œ
                decode_q.push(seq)

    # 4) ë©”ëª¨ë¦¬ ì••ë ¥ í•´ì†Œ (e.g., OOM ì˜ˆë°©/íšŒìˆ˜)
    if kv_cache.pressure_high():
        evict_policies_run()  # ëë‚œ seq íšŒìˆ˜, ë¯¸ì‚¬ìš© í˜ì´ì§€ ë°˜í™˜, low-priority seq delay ë“±
```

> í¬ì¸íŠ¸
>
> * **Prefill ë¨¼ì €** í° ë©ì–´ë¦¬ë¡œ ë¬¶ì–´ KVë¥¼ â€œí•œ ë°©ì—â€ ì±„ìš°ê³ ,
> * ê·¸ ë‹¤ìŒ **Decode**ë¥¼ ë‹¤ìˆ˜ ì‹œí€€ìŠ¤ì˜ **ë§ˆì§€ë§‰ í† í°ë“¤**ë¡œ ë¬¶ì–´ **í•œ ìŠ¤í… ì „íŒŒ**
> * ë‘˜ ë‹¤ **í† í°/ë©”ëª¨ë¦¬ ì˜ˆì‚°**ì„ ê³„ì‚°í•´ batch í¬ê¸°ë¥¼ ì˜ì‚¬ê²°ì •

# 4) vLLMì—ì„œì˜ êµ¬í˜„ í¬ì¸íŠ¸

* **Paged KV Cache**: KVë¥¼ ê³ ì • í¬ê¸° **í˜ì´ì§€** ë‹¨ìœ„ë¡œ ê´€ë¦¬ â†’ ê¸´ í”„ë¡¬í”„íŠ¸/ë§ì€ ë™ì‹œ ì„¸ì…˜ë„ **ë©”ëª¨ë¦¬ ë‹¨í¸í™”â†“**
* **Continuous Batching**: í”„ë¡¬í”„íŠ¸ ê¸¸ì´/ìƒì„± ê¸¸ì´ê°€ ë‹¤ë¥¸ ì‹œí€€ìŠ¤ë¥¼ **prefill ë‹¨ê³„ì™€ decode ë‹¨ê³„ë¥¼ ë¶„ë¦¬**í•´ì„œ ë§¤ ìŠ¤í… ìµœì  ì¡°í•©ìœ¼ë¡œ ë¬¶ìŒ
* **Scheduler ì •ì±…**(ìš”ì§€)

  * **í† í° ì˜ˆì‚° ê¸°ë°˜**: í•œ ìŠ¤í…ì— í—ˆìš© ê°€ëŠ¥í•œ total tokensì™€ KV page ì—¬ìœ ë¥¼ ê¸°ì¤€ìœ¼ë¡œ batch í¬ê¸° ê²°ì •
  * **Prefill/Decode time-slice**: ì§§ì€ í”„ë¡¬í”„íŠ¸ê°€ ì˜¤ë˜ ëŒ€ê¸°í•˜ì§€ ì•Šë„ë¡ **prefill ë¹ˆë„**ë„ ë³´ì¥
* (ì˜µì…˜ ì˜ˆì‹œ)

  * `--max-num-seqs` / `--gpu-memory-utilization` : í™œì„± ì‹œí€€ìŠ¤/ë©”ëª¨ë¦¬ ìƒí•œ
  * `--max-logprobs` / `--max-num-batched-tokens` : ë°°ì¹˜ í† í° ì˜ˆì‚°
  * speculative, beams, parallel sampling ë“±ê³¼ë„ ì¡°í•©

# 5) sGLangì—ì„œì˜ í¬ì¸íŠ¸(ìš”ì§€)

* **ë½-í”„ë¦¬/ë‚®ì€ ì˜¤ë²„í—¤ë“œ ëŸ°íƒ€ì„** ì§€í–¥, fine-grained ìŠ¤ì¼€ì¤„ë§
* Prefillê³¼ Decodeë¥¼ **ë…ë¦½ í**ë¡œ ë‘ê³ , **ë ˆì´í„´ì‹œ ë¯¼ê°í•œ decode ìŠ¤í…ì— ìš°ì„ ê¶Œ**ì„ ì£¼ë˜, prefill starvation ë°©ì§€
* ì»¤ìŠ¤í…€ **program DAG/graph** ìƒì—ì„œ LLM í˜¸ì¶œì„ ë…¸ë“œë¡œ ë³´ê³ , **ë…¸ë“œ ê°„ KV ìºì‹œ ì¬ì‚¬ìš©** ìµœì í™”

# 6) ì‹¤ì œ í•œ ìŠ¤í…ì´ í•˜ëŠ” ì¼ (Decode)

```
[sequences: Nê°œ]  â”€â”€(ë§ˆì§€ë§‰ í† í°ë“¤ ëª¨ìŒ)â”€â”€>  [Embedding + PosEnc]
      â”‚                                 â”‚
      â””â”€â”€â”€â”€â”€ shared KV (prefill ë•Œ ìƒì„±) â”€â”˜
                    â”‚
             [Transformer Layers]
                    â”‚
                 [Logits]
                    â”‚
               [Sample/Top-k]
                    â”‚
           [Append â†’ stop? â†’ ì¬ì‚½ì…/ì¢…ë£Œ]
```

* DecodeëŠ” **ì§ì „ í† í° 1ê°œë§Œ** ìƒˆë¡œ ì „íŒŒ, ë‚˜ë¨¸ì§€ëŠ” **KV ìºì‹œ ì¬ì‚¬ìš©**
* ê·¸ë˜ì„œ **KV ë©”ëª¨ë¦¬ ëŒ€ì—­í­**ê³¼ **ìºì‹œ í˜ì´ì§€ ì ‘ê·¼**ì´ ë³‘ëª©ì´ ë˜ê¸° ì‰¬ì›€ â†’ **paged KV**ì™€ **ì •ë ¬ëœ batch êµ¬ì„±**ì´ ì¤‘ìš”

# 7) Speculative Decodingê³¼ì˜ ê²°í•©(ì„ íƒ)

* **Draft ëª¨ë¸**ë¡œ ì—¬ëŸ¬ í† í°ì„ ë¯¸ë¦¬ ì œì•ˆ â†’ ë©”ì¸ ëª¨ë¸ì´ **í•œ ë²ˆì˜ stepì—ì„œ ì—¬ëŸ¬ í† í° ê²€ì¦**
* Prefill/Decode ë¶„ë¦¬ êµ¬ì¡° ë•ë¶„ì—, ê²€ì¦ ìì²´ë¥¼ **decode ìŠ¤í…ì˜ í™•ì¥íŒ**ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ëŸ¬ì— ì–¹ê¸° ì¢‹ìŒ
* ì¥ì : **í† í°/ìŠ¤í… ìˆ˜ ê°ì†Œ â†’ ë ˆì´í„´ì‹œâ†“**

# 8) ë¹ˆë²ˆí•œ ì´ìŠˆ & í•´ê²° íŒ

* **Prefillì´ ê¸¸ì–´ decodeê°€ êµ¶ëŠ” ë¬¸ì œ**: ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ **prefillâ€“decode ë¹„ìœ¨ ê°€ë“œ**(ì˜ˆ: íƒ€ì„ìŠ¬ë¼ì´ìŠ¤, max prefill tokens/step)
* **OOM/ë©”ëª¨ë¦¬ ì••ë ¥**: `paged_kv` í™œì„±, **max active seqs** ì œí•œ, **KV eviction ì •ì±…**(ì¢…ë£Œ ì¦‰ì‹œ íšŒìˆ˜, low-priority ì§€ì—°)
* **ì§§ì€ ìš”ì²­ì´ ê¸´ ìš”ì²­ì— ëŒë ¤ ëŠë ¤ì§**: **length-based bucketing**ìœ¼ë¡œ ìœ ì‚¬ ê¸¸ì´ë¼ë¦¬ ë¬¶ì–´ prefill/step êµ¬ì„±
* **Throughput vs Latency íŠ¸ë ˆì´ë“œì˜¤í”„**:

  * ëŒ€ëŸ‰ ì˜¤í”„ë¼ì¸/ë°°ì¹˜í˜•: prefill í¬ê²Œ, decode ë¬¶ìŒ í¬ê²Œ
  * ëŒ€í™”í˜•: decode batchëŠ” ì‘ê²Œ, prefill íƒ€ì„ìŠ¬ë¼ì´ìŠ¤ ì§§ê²Œ

# 9) ê°„ë‹¨í•œ ì„¤ì • ê°€ì´ë“œ(ê°ê°ì¹˜)

* **ëŒ€í™”í˜•(ì§§ì€ ë‹µë³€, ë§ì€ ë™ì‹œ ì‚¬ìš©ì)**

  * vLLM: `--gpu-memory-utilization 0.85`
    `--max-num-seqs` ì ë‹¹ (ìˆ˜ë°±), decode batch ì‘ê²Œ(ë ˆì´í„°ì‹œ ìš°ì„ )
    speculative on(ê°€ëŠ¥í•˜ë©´)
* **ë¶„ì„/ìš”ì•½(ê¸´ í”„ë¡¬í”„íŠ¸, ì¤‘ê°„ ê¸¸ì´ ìƒì„±)**

  * prefill í† í° ì˜ˆì‚° ë„‰ë„‰íˆ, **prefill ìš°ì„  ìŠ¤ì¼€ì¤„**
  * decodeëŠ” length-bucketingìœ¼ë¡œ step íš¨ìœ¨í™”
* **ìŠ¤íŠ¸ë¦¬ë°**: step ì£¼ê¸° ì§§ê²Œ, **decode ë¹ˆë„ ë†’ê²Œ**

# 10) ë¯¸ë‹ˆ ì˜ì‚¬ì½”ë“œ(ì—°ì‚°/ë©”ëª¨ë¦¬ ì˜ˆì‚° í¬í•¨)

```python
TOKENS_BUDGET_PER_FORWARD = 8192   # ì˜ˆ: ëª¨ë¸/í•˜ë“œì›¨ì–´ë³„ ê²½í—˜ê°’
MAX_ACTIVE_SEQS = 256

def make_prefill_batch(q, budget):
    batch, used = [], 0
    while q and used + q.peek().prompt_len <= budget:
        req = q.pop()
        batch.append(req)
        used += req.prompt_len
    return pack_prefill(batch)  # pad/pack, position ids ê³„ì‚°

def make_decode_batch(q, max_seqs, budget):
    batch, used = [], 0
    while q and len(batch) < max_seqs:
        seq = q.pop()
        # decodeëŠ” ë³´í†µ 1 token/seq, í•˜ì§€ë§Œ KV ê¸¸ì´ì— ë”°ë¼ attn cost ì¶”ì •
        step_cost = est_attn_cost(seq.context_len)  # ì˜ˆ: O(context_len)
        if used + step_cost > budget: break
        batch.append(seq); used += step_cost
    return pack_decode(batch)   # ë§ˆì§€ë§‰ í† í°ë§Œ ëª¨ì•„ í…ì„œí™”

while True:
    # fairness: decode í•œ ë²ˆ, prefill í•œ ë²ˆ ì‹ìœ¼ë¡œ ë¼ìš´ë“œ-ë¡œë¹ˆë„ ê°€ëŠ¥
    if should_run_decode():
        step = make_decode_batch(decode_q, MAX_ACTIVE_SEQS, TOKENS_BUDGET_PER_FORWARD)
        run_decode_step(step)
    if should_run_prefill():
        pb = make_prefill_batch(prefill_q, TOKENS_BUDGET_PER_FORWARD)
        run_prefill(pb)
```

---

í•„ìš”í•˜ì‹œë©´, \*\*ë‹¹ì‹ ì´ ì“°ëŠ” ì„¸íŒ…(vLLMì¸ì§€ sGLangì¸ì§€, GPU/VRAM, ê¸°ëŒ€ ë™ì ‘, ìš”ì²­ ê¸¸ì´ ë¶„í¬)\*\*ì— ë§ì¶° \*\*ê¶Œì¥ ìŠ¤ì¼€ì¤„ëŸ¬ íŒŒë¼ë¯¸í„°(í† í° ì˜ˆì‚°, batch í¬ê¸°, speculative on/off)\*\*ë¥¼ ë°”ë¡œ ì‚°ì¶œí•´ì„œ ë“œë¦´ê²Œìš”.


## ì°¸ê³ 
- NVIDIA Dynamo, ëŒ€ê·œëª¨ ë¶„ì‚° ì¶”ë¡  ë°œì „ì„ ìœ„í•œ llm-d ì»¤ë®¤ë‹ˆí‹° ì´ë‹ˆì…”í‹°ë¸Œ ê°€ì†í™” : https://developer.nvidia.com/ko-kr/blog/nvidia-dynamo-accelerates-llm-d-community-initiatives-for-advancing-large-scale-distributed-inference/